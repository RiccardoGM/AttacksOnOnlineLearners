{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd7ac25-9549-40fb-95e7-704828689c02",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08eb9240-adde-4fb5-8cd4-dd5c1db39b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy, matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Stable baselines\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "\n",
    "# Custom modules\n",
    "import sys\n",
    "import os\n",
    "local_path = '/Users/riccardo/Documents/GitHub/' #'path_to_progect_folder/'\n",
    "sys.path.append(local_path+'OptimalControlAttacks/SyntheticDataExperiments/')\n",
    "from Modules import AuxiliaryFunctions as AF\n",
    "from Modules import GreedyAttacks as GA\n",
    "from Modules import DeepRLAttacks as RLA\n",
    "from Parameters import ParametersAttacksComparison_2LayerNN as Par"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5114b71d-1496-477a-8844-0699f5d46689",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f559bc37-a2b8-4bcc-9f8b-bee3a6a7ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "orange = '#F5A962'\n",
    "light_blue = '#3C8DAD'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4618589-fcac-4a8e-9a86-5b6930378729",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bffa8b21-e7a8-4dce-9a29-7938df096043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = Par.model_name\n",
    "activation = Par.activation\n",
    "output_scaling = Par.output_scaling\n",
    "hiddenlayer_width = Par.hiddenlayer_width\n",
    "target_type = Par.target_type\n",
    "train_first_layer = Par.train_first_layer\n",
    "\n",
    "# Input data parameters\n",
    "dim_input = Par.dim_input\n",
    "batch_size = Par.batch_size\n",
    "mu_x = Par.mu_x\n",
    "sigma_x = Par.sigma_x\n",
    "n_runs_experiments = Par.n_runs_experiments\n",
    "\n",
    "# Dynamics parameters\n",
    "learning_rate = Par.learning_rate\n",
    "gamma = Par.gamma\n",
    "beta = Par.beta\n",
    "\n",
    "# N. samples\n",
    "n_timesteps = Par.n_timesteps\n",
    "n_timesteps_transient_th = Par.n_timesteps_transient_th\n",
    "n_timesteps_past = Par.n_timesteps_past\n",
    "n_samples_average = Par.n_samples_average\n",
    "n_samples_buffer = Par.n_samples_buffer\n",
    "n_samples_test = Par.n_samples_test\n",
    "time_window = Par.time_window\n",
    "\n",
    "# Control parameters\n",
    "a_min = Par.a_min\n",
    "a_max = Par.a_max\n",
    "n_a_gridpoints = Par.n_a_gridpoints\n",
    "n_runs_calibration = Par.n_runs_calibration\n",
    "control_cost_weight = Par.control_cost_weight\n",
    "greedy_weight_future = Par.greedy_weight_future\n",
    "opt_pref = Par.opt_pref\n",
    "fut_pref = Par.fut_pref\n",
    "\n",
    "# DeepRL Agent\n",
    "agent_model_name = Par.agent_model_name\n",
    "n_actions = Par.n_actions\n",
    "use_action_noise = Par.use_action_noise\n",
    "action_noise_mean = Par.action_noise_mean\n",
    "action_noise_std = Par.action_noise_std\n",
    "observation_type = Par.observation_type \n",
    "use_small_achitecture = Par.use_small_achitecture\n",
    "shuffle_array = Par.shuffle_array\n",
    "learning_rate_agent = Par.learning_rate_agent\n",
    "activation_fn = Par.activation_fn\n",
    "n_episodes = Par.n_episodes\n",
    "save_freq = Par.save_freq\n",
    "train_freq = Par.train_freq\n",
    "\n",
    "# Strings/paths\n",
    "experiment_description = Par.experiment_description\n",
    "path_agent = Par.path_agent\n",
    "export_path = Par.export_path\n",
    "rlmodels_path = Par.rlmodels_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94cacbe8-0bec-4d2f-a891-2f2d7672e67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_input: 10\n",
      "hiddenlayer_width: 100\n",
      "output_scaling: inv_sqroot\n",
      "target_type: FlippedTeacher\n",
      "batch_size: 1\n",
      "activation: Erf\n",
      "a min: -2\n",
      "a max: 3\n",
      "observation_type: lastlayer\n",
      "control_cost_weight: 1.0\n",
      "N past timesteps: 10000\n"
     ]
    }
   ],
   "source": [
    "print('dim_input:', dim_input)\n",
    "print('hiddenlayer_width:', hiddenlayer_width)\n",
    "print('output_scaling:', output_scaling)\n",
    "print('target_type:', target_type)\n",
    "print('batch_size:', batch_size)\n",
    "print('activation:', activation)\n",
    "print('a min:', a_min)\n",
    "print('a max:', a_max)\n",
    "print('observation_type:', observation_type)\n",
    "print('control_cost_weight:', control_cost_weight)\n",
    "print('N past timesteps:', n_timesteps_past)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62c2160-13a5-4433-ba82-5c74f531ebbe",
   "metadata": {},
   "source": [
    "# Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25fdce99-5e89-4ca0-820a-f8341fd34beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "np.random.seed(seed=0)\n",
    "\n",
    "# Teacher\n",
    "W_teach = np.random.normal(0, 1, (hiddenlayer_width, dim_input))\n",
    "W_teach = W_teach / (np.sum(W_teach**2, axis=1).reshape(-1,1).repeat(dim_input, axis=1)/dim_input)**0.5\n",
    "v_teach = np.random.normal(0, 1, hiddenlayer_width)\n",
    "v_teach = v_teach / ((np.sum(v_teach**2)/hiddenlayer_width))**0.5\n",
    "# Target\n",
    "if target_type=='FlippedTeacher':\n",
    "    W_target = W_teach.copy()\n",
    "    v_target = -v_teach.copy()\n",
    "elif target_type=='Random':\n",
    "    W_target = np.random.normal(0, 1, (hiddenlayer_width, dim_input))\n",
    "    W_target = W_target / (np.sum(W_target**2, axis=1).reshape(-1,1).repeat(dim_input, axis=1)/dim_input)**0.5\n",
    "    v_target = np.random.normal(0, 1, hiddenlayer_width)\n",
    "    v_target = v_target / ((np.sum(v_target**2)/hiddenlayer_width))**0.5\n",
    "# Student (initial condition)\n",
    "W_stud_0 = W_teach.copy()\n",
    "v_stud_0 = v_teach.copy()\n",
    "            \n",
    "# Arrays (assuming batch_size as specified above)\n",
    "x_incoming_arr = np.random.normal(mu_x, sigma_x, (n_runs_experiments, batch_size*n_timesteps, dim_input))\n",
    "x_past = np.random.normal(mu_x, sigma_x, (batch_size*n_timesteps_past, dim_input))\n",
    "x_buffer = np.random.normal(mu_x, sigma_x, (batch_size*n_samples_buffer, dim_input))\n",
    "x_test = np.random.normal(mu_x, sigma_x, (batch_size*n_samples_test, dim_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a74ee2-f560-4fc6-8ac6-23a23e85c8a3",
   "metadata": {},
   "source": [
    "# Weight action cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "788bb0da-8267-402b-afd6-d1a73cbff836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-factor control cost: 3.24\n"
     ]
    }
   ],
   "source": [
    "label_t_test = GA.NN2L(x_test, W_teach, v_teach, activation=activation, output_scaling=output_scaling)\n",
    "label_o_test = GA.NN2L(x_test, W_target, v_target, activation=activation, output_scaling=output_scaling)\n",
    "error_target_teach = np.mean((label_o_test-label_t_test)**2)\n",
    "d_target_teach = 0.5 * error_target_teach\n",
    "pref_control_cost_weight = (2*d_target_teach)\n",
    "print('Pre-factor control cost: %.2f' % pref_control_cost_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aa3246-8abc-4ea4-9ba9-faedc9974514",
   "metadata": {},
   "source": [
    "## Check environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3387dd4a-209a-47a4-8c76-7d2e760cf46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle past stream: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/OptimalControlAttacks/lib/python3.8/site-packages/stable_baselines3/common/env_checker.py:428: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('Shuffle past stream:', shuffle_array)\n",
    "env = RLA.EnvironmentNN2L(observation_type=observation_type,\n",
    "                          x_arr=x_past,\n",
    "                          batch_size=batch_size,\n",
    "                          W_stud_0=W_stud_0, \n",
    "                          v_stud_0=v_stud_0,\n",
    "                          W_teach=W_teach, \n",
    "                          v_teach=v_teach, \n",
    "                          W_target=W_target, \n",
    "                          v_target=v_target, \n",
    "                          a_min=a_min,\n",
    "                          a_max=a_max,\n",
    "                          learning_rate=learning_rate, \n",
    "                          control_cost_weight=pref_control_cost_weight*control_cost_weight, \n",
    "                          activation=activation,\n",
    "                          shuffle_array=shuffle_array, \n",
    "                          outputscaling=output_scaling, \n",
    "                          train_first_layer=train_first_layer)\n",
    "\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9244746b-a523-4ed5-9014-f200904aded2",
   "metadata": {},
   "source": [
    "# RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01092f40-37ae-4e4a-98a7-202f1b7339d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New TD3 agent created\n"
     ]
    }
   ],
   "source": [
    "# Small architecture\n",
    "if use_small_achitecture:\n",
    "    print('Using custom small architecture for policy and value!')\n",
    "    custom_net_kwargs = dict(activation_fn=activation_fn, net_arch=dict(pi=[10, 10], qf=[10, 10]))\n",
    "else:\n",
    "    custom_net_kwargs = None\n",
    "         \n",
    "# Create model\n",
    "if agent_model_name=='TD3':\n",
    "    \n",
    "        if use_action_noise:\n",
    "            action_noise = NormalActionNoise(mean=action_noise_mean, sigma=action_noise_std)\n",
    "        else:\n",
    "            action_noise = None  \n",
    "            \n",
    "        model = TD3(\"MlpPolicy\", \n",
    "                    env,\n",
    "                    action_noise=action_noise,\n",
    "                    verbose=0, \n",
    "                    gamma=gamma,\n",
    "                    learning_rate=learning_rate_agent, \n",
    "                    policy_kwargs=custom_net_kwargs,\n",
    "                    train_freq=train_freq, \n",
    "                    gradient_steps=train_freq)\n",
    "        print('New %s agent created' % agent_model_name)\n",
    "else:\n",
    "    raise ValueError('Agent type other than TD3 not available/tested')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2dd4e-0be8-4b4c-84ed-0a11014ea226",
   "metadata": {},
   "source": [
    "# Training agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9c65c75-1342-452c-9595-2973254964a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timesteps for each episode: 10000\n",
      "Episode: 1/8\n",
      "Episode: 2/8\n",
      "Episode: 3/8\n",
      "Episode: 4/8\n",
      "Episode: 5/8\n",
      "Episode: 6/8\n",
      "Episode: 7/8\n",
      "Episode: 8/8\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "print('timesteps for each episode:', n_timesteps_past)\n",
    "\n",
    "# Save a checkpoint \n",
    "checkpoint_callback = CheckpointCallback(\n",
    "  save_freq=save_freq,\n",
    "  save_path=path_agent,\n",
    "  name_prefix=\"rl_model\",\n",
    "  save_replay_buffer=False,\n",
    "  save_vecnormalize=True,\n",
    ")\n",
    "\n",
    "for ep in range(n_episodes):\n",
    "    print('Episode: %d/%d'%(ep+1, n_episodes))\n",
    "    model.learn(total_timesteps=n_timesteps_past, \n",
    "                progress_bar=False, \n",
    "                reset_num_timesteps=False,\n",
    "                tb_log_name='DeepRL', \n",
    "                log_interval=1, \n",
    "                callback=checkpoint_callback)\n",
    "        \n",
    "print('Training completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf258824-0032-4df3-a232-5011374a5834",
   "metadata": {},
   "source": [
    "## Compute training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90a8b78d-878c-4243-b0ab-17df62b9e620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found: 0 steps (episode 1)\n",
      "Model: 1000 steps (episode 1)\n",
      "Model: 2000 steps (episode 1)\n",
      "Model: 3000 steps (episode 1)\n",
      "Model: 4000 steps (episode 1)\n",
      "Model: 5000 steps (episode 1)\n",
      "Model: 6000 steps (episode 1)\n",
      "Model: 7000 steps (episode 1)\n",
      "Model: 8000 steps (episode 1)\n",
      "Model: 9000 steps (episode 1)\n",
      "Model: 10000 steps (episode 1)\n",
      "Model: 10000 steps (episode 2)\n",
      "Model: 11000 steps (episode 2)\n",
      "Model: 12000 steps (episode 2)\n",
      "Model: 13000 steps (episode 2)\n",
      "Model: 14000 steps (episode 2)\n",
      "Model: 15000 steps (episode 2)\n",
      "Model: 16000 steps (episode 2)\n",
      "Model: 17000 steps (episode 2)\n",
      "Model: 18000 steps (episode 2)\n",
      "Model: 19000 steps (episode 2)\n",
      "Model: 20000 steps (episode 2)\n",
      "Model: 20000 steps (episode 3)\n",
      "Model: 21000 steps (episode 3)\n",
      "Model: 22000 steps (episode 3)\n",
      "Model: 23000 steps (episode 3)\n",
      "Model: 24000 steps (episode 3)\n",
      "Model: 25000 steps (episode 3)\n",
      "Model: 26000 steps (episode 3)\n",
      "Model: 27000 steps (episode 3)\n",
      "Model: 28000 steps (episode 3)\n",
      "Model: 29000 steps (episode 3)\n",
      "Model: 30000 steps (episode 3)\n",
      "Model: 30000 steps (episode 4)\n",
      "Model: 31000 steps (episode 4)\n",
      "Model: 32000 steps (episode 4)\n",
      "Model: 33000 steps (episode 4)\n",
      "Model: 34000 steps (episode 4)\n",
      "Model: 35000 steps (episode 4)\n",
      "Model: 36000 steps (episode 4)\n",
      "Model: 37000 steps (episode 4)\n",
      "Model: 38000 steps (episode 4)\n",
      "Model: 39000 steps (episode 4)\n",
      "Model: 40000 steps (episode 4)\n",
      "Model: 40000 steps (episode 5)\n",
      "Model: 41000 steps (episode 5)\n",
      "Model: 42000 steps (episode 5)\n",
      "Model: 43000 steps (episode 5)\n",
      "Model: 44000 steps (episode 5)\n",
      "Model: 45000 steps (episode 5)\n",
      "Model: 46000 steps (episode 5)\n",
      "Model: 47000 steps (episode 5)\n",
      "Model: 48000 steps (episode 5)\n",
      "Model: 49000 steps (episode 5)\n",
      "Model: 50000 steps (episode 5)\n",
      "Model: 50000 steps (episode 6)\n",
      "Model: 51000 steps (episode 6)\n",
      "Model: 52000 steps (episode 6)\n",
      "Model: 53000 steps (episode 6)\n",
      "Model: 54000 steps (episode 6)\n",
      "Model: 55000 steps (episode 6)\n",
      "Model: 56000 steps (episode 6)\n",
      "Model: 57000 steps (episode 6)\n",
      "Model: 58000 steps (episode 6)\n",
      "Model: 59000 steps (episode 6)\n",
      "Model: 60000 steps (episode 6)\n",
      "Model: 60000 steps (episode 7)\n",
      "Model: 61000 steps (episode 7)\n",
      "Model: 62000 steps (episode 7)\n",
      "Model: 63000 steps (episode 7)\n",
      "Model: 64000 steps (episode 7)\n",
      "Model: 65000 steps (episode 7)\n",
      "Model: 66000 steps (episode 7)\n",
      "Model: 67000 steps (episode 7)\n",
      "Model: 68000 steps (episode 7)\n",
      "Model: 69000 steps (episode 7)\n",
      "Model: 70000 steps (episode 7)\n",
      "Model: 70000 steps (episode 8)\n",
      "Model: 71000 steps (episode 8)\n",
      "Model: 72000 steps (episode 8)\n",
      "Model: 73000 steps (episode 8)\n",
      "Model: 74000 steps (episode 8)\n",
      "Model: 75000 steps (episode 8)\n",
      "Model: 76000 steps (episode 8)\n",
      "Model: 77000 steps (episode 8)\n",
      "Model: 78000 steps (episode 8)\n",
      "Model: 79000 steps (episode 8)\n",
      "Model: 80000 steps (episode 8)\n"
     ]
    }
   ],
   "source": [
    "timesteps = n_timesteps_past\n",
    "\n",
    "steps = []\n",
    "rew_disc_av = []\n",
    "\n",
    "# Test environment\n",
    "env = RLA.EnvironmentNN2L(observation_type=observation_type,\n",
    "                          x_arr=x_test,\n",
    "                          batch_size=batch_size,\n",
    "                          W_stud_0=W_stud_0, \n",
    "                          v_stud_0=v_stud_0,\n",
    "                          W_teach=W_teach, \n",
    "                          v_teach=v_teach, \n",
    "                          W_target=W_target, \n",
    "                          v_target=v_target, \n",
    "                          a_min=a_min,\n",
    "                          a_max=a_max,\n",
    "                          learning_rate=learning_rate, \n",
    "                          control_cost_weight=pref_control_cost_weight*control_cost_weight, \n",
    "                          activation=activation,\n",
    "                          shuffle_array=shuffle_array, \n",
    "                          outputscaling=output_scaling, \n",
    "                          train_first_layer=train_first_layer)\n",
    "# Testing\n",
    "for ep in range(n_episodes):\n",
    "    \n",
    "    for t in range(0, timesteps+1, save_freq):\n",
    "        \n",
    "        timesteps_past = ep*timesteps + t\n",
    "        steps_flag = False\n",
    "\n",
    "        if agent_model_name=='TD3':\n",
    "            path_to_model = path_agent + f'/rl_model_{timesteps_past}_steps.zip'\n",
    "            #path_to_buffer = path_repbuffer + f'rl_model_replay_buffer_{timesteps_past}_steps.pkl'\n",
    "            if os.path.exists(path_to_model):\n",
    "                model_iter = TD3.load(path_to_model, env)\n",
    "                #model_iter.load_replay_buffer(path_to_buffer)\n",
    "                print('Model: %d steps (episode %d)' % (timesteps_past, ep+1)) \n",
    "                steps_flag = True\n",
    "            else:\n",
    "                print('Model not found: %d steps (episode %d)' % (timesteps_past, ep+1)) \n",
    "\n",
    "        if steps_flag:\n",
    "            reward_list = []\n",
    "            obs, info = env.reset()\n",
    "            terminated = False\n",
    "            while not terminated:\n",
    "                action, _ = model_iter.predict(obs, deterministic=True)\n",
    "                obs, reward, terminated, truncated, info = env.step(action)\n",
    "                if env.timestep>=n_timesteps - time_window:\n",
    "                    reward_list.append(reward)\n",
    "                    \n",
    "            rew_disc_av.append(np.mean(np.array(reward_list, dtype=object)))\n",
    "            steps.append(timesteps_past)\n",
    "        \n",
    "objective = -np.array(rew_disc_av, dtype=object)\n",
    "steps = np.array(steps, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ef679-54b9-4f7f-b9ac-0ddea8a05ad6",
   "metadata": {},
   "source": [
    "## Export training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7d79a43-5a17-4632-86b4-55cd60f9d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_description = '_agent#%s' % (agent_model_name)\n",
    "name = 'ObjectiveVSTrainingSteps'\n",
    "filename = name + '_@@@' + models_description + experiment_description\n",
    "data_to_export = objective\n",
    "np.save(rlmodels_path + filename, data_to_export)\n",
    "\n",
    "\n",
    "models_description = '_agent#%s' % (agent_model_name)\n",
    "name = 'TrainingSteps'\n",
    "filename = name + '_@@@' + models_description + experiment_description\n",
    "data_to_export = steps\n",
    "np.save(rlmodels_path + filename, data_to_export)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a83423e-3a8d-4695-b612-361150096643",
   "metadata": {},
   "source": [
    "## Plot training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f53338c-f18f-4582-90f4-4bcbc37d24b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5487366116756446, 9999)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Greedy average reward\n",
    "if activation=='Linear':\n",
    "    pref_fut = 1.\n",
    "elif activation=='Erf':\n",
    "    pref_fut = 1.6 # 2\n",
    "reward_greedy_list = []\n",
    "\n",
    "# Greedy experiment\n",
    "obs, info = env.reset()\n",
    "W_stud = env.W_stud\n",
    "v_stud = env.v_stud\n",
    "x_batch = env.x_batch\n",
    "terminated = False\n",
    "while not terminated:\n",
    "    action = GA.a_greedy_NN2L(W_stud=W_stud,\n",
    "                              v_stud=v_stud,\n",
    "                              W_target=W_target,\n",
    "                              v_target=v_target,\n",
    "                              W_teach=W_teach,\n",
    "                              v_teach=v_teach,\n",
    "                              x_batch=x_batch,\n",
    "                              x_buffer=x_buffer,\n",
    "                              dim_input=dim_input,\n",
    "                              eta=learning_rate,\n",
    "                              weight_future=pref_fut*dim_input/learning_rate,\n",
    "                              a_min=a_min,\n",
    "                              a_max=a_max,\n",
    "                              n_gridpoints=n_a_gridpoints,\n",
    "                              control_cost_weight=pref_control_cost_weight*control_cost_weight,\n",
    "                              activation=activation,\n",
    "                              train_first_layer=train_first_layer,\n",
    "                              output_scaling=output_scaling)\n",
    "    \n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    W_stud, v_stud = env.W_stud, env.v_stud\n",
    "    x_batch = env.x_batch\n",
    "    if env.timestep>=n_timesteps - time_window:\n",
    "        reward_greedy_list.append(reward)\n",
    "    if env.timestep%100==0:\n",
    "        print(env.timestep)\n",
    "    \n",
    "objective_greedy = -np.mean(np.array(reward_greedy_list, dtype=object))\n",
    "objective_greedy, env.timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f3f6fe6-6357-4b35-aab3-b5a685ea9e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72000, 0.5610655517715738)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find best model\n",
    "best_model_t = steps[np.argmin(objective)]\n",
    "best_model_obj = objective[np.argmin(objective)]\n",
    "best_model_t, best_model_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd0b25be-a4b0-4c7d-9d33-3b2e7472809a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 261x191.4 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AF.SetPlotParams(magnification=.9, ratio=float(2.2/3.), fontsize=11, lines_w=.7, ms=7)\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rc('text', usetex = True)\n",
    "mpl.rc('text.latex', preamble=r'\\usepackage{sfmath}')\n",
    "\n",
    "\n",
    "plt.axhline(objective_greedy, color='black', ls=':', lw=.8, label='greedy')\n",
    "plt.plot(steps+1, objective, color=orange)\n",
    "plt.plot(best_model_t, best_model_obj, color=light_blue, ls='', marker='.', ms=8)\n",
    "\n",
    "plt.ylabel('$g^{\\mathrm{RL}}_{\\infty}$')\n",
    "plt.xlabel('n. episodes')\n",
    "plt.xlim([-n_timesteps_past/4, n_episodes*n_timesteps_past])\n",
    "x_positions_ticks = np.linspace(0, n_episodes, n_episodes//2+1)*n_timesteps_past\n",
    "x_ticks_labels = [int(x) for x in np.linspace(0, n_episodes, n_episodes//2+1)]\n",
    "plt.xticks(x_positions_ticks, x_ticks_labels)\n",
    "plt.yticks([0.5, 1., 1.5, 2.])\n",
    "plt.ylim([0.5, 2.])\n",
    "plt.grid(False)\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OptimalControlAttaks",
   "language": "python",
   "name": "optimalcontrolattaks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
